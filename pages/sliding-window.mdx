import Visualizer from '../components/Visualizer'
import Item from '../components/shared/Item'
import * as Figures from '../components/sliding-window'
import snapshot from '../lib/snapshot.macro'

# The Sliding Window Pattern

The sliding window pattern is a neat and simple pattern to optimize problems involving _subarrays_. Let's go over a simple problem to see how this can be useful.

For this problem, we are given an array `arr`, and a subarray size `k`, and we are asked to find the _average_ of _all_ subarrays in `arr` of size `k`. So given an array like `[1, 2, 3, 4]` and a subarray size `k = 2`, the correct answer would be `[1.5, 2.5, 3.5]` because:

- `[1, 2, 3, 4]` has three subarrays of size 2, namely `[1, 2], [2, 3], [3, 4]`.
- The average of the first subarray is `1 + 2 / 2 = 1.5`, the average of the second is `2.5` (using the same formula), and the average of the third is `3.5`.
- Putting this together we get the final result `[1.5, 2.5, 3.5]`.

Given these steps, it seems pretty clear that in designing an algorithm to solve this problem we would have to (1) iterate through every subarray then (2) find the average of each and append it to the result array.

A straightforward way to find every subarray of an array is to iterate through each index of the array and _construct_ the subarray that begins at that index by iterating `k` more times. In this second iteration we can also sum up the numbers to compute the resulting average. Here's what that would look like:

<Visualizer
  initialInputs={[[1, 2, 3, 4]]}
  algorithm={snapshot((arr) => {
    let sum = 0
    const window = []
    for (let i = 1; i < 4; i++) {
      sum += arr[i]
      window.push(i)
      debugger
    }
    return sum
  })}
>
  {({ state }) => (
    <React.Fragment>
      <div className="flex w-full justify-center">
        {state.arr.map((item, index) => (
          <Item key={index} active={state.window.includes(index)}>
            {item}
          </Item>
        ))}
      </div>
      <p className="font-mono w-full text-center mt-4">
        k = 2 sum: {state.sum}
      </p>
    </React.Fragment>
  )}
</Visualizer>

Doing that for _every_ index in the array, we get the final algorithm:

<Visualizer
  initialInputs={[[1, 2, 3, 4, 5, 6], 3]}
  algorithm={snapshot((arr, k) => {
    const result = []
    for (let i = 0; i <= arr.length - k; i++) {
      let sum = 0
      for (let j = 0; j < k; j++) {
        sum += arr[i + j]
        debugger
      }
      result.push(sum / k)
    }
    debugger
    return result
  })}
  caption="This is an interactive demo! Press the pencil icon to change the values of arr and k."
  editable
>
  {(context) => <Figures.Quadratic {...context} />}
</Visualizer>

Notice the number on the top right of the animation. This number represents the total number of steps required to compute the result given the inputs `arr` and `k`. Try adding two more items and see how that number changes‚Äîit went up, by a _lot_.

Is there a better way?

Looking back at the algorithm, notice that most of the time we're counting numbers that we've already included before. Let's look at the animation again, this time highlighting all the double counts in red:

<Visualizer
  initialInputs={[[1, 2, 3, 4, 5, 6], 3]}
  algorithm={snapshot((arr, k) => {
    const result = []
    const counted = []
    const doubleCounted = []
    for (let i = 0; i <= arr.length - k; i++) {
      const subarray = [i]
      let sum = 0
      for (let j = 0; j < k; j++) {
        subarray.push(i + j)
        sum += arr[i + j]
        if (counted.includes(i + j)) {
          doubleCounted.push(i + j)
        }
        debugger
      }
      subarray.forEach((item) => counted.push(item))
      result.push(sum / k)
    }
    debugger
    return result
  })}
  editable
>
  {(context) => <Figures.DoubleCount {...context} />}
</Visualizer>

When the algorithm finishes, only 2 elements **were not double counted!** It turns out that no matter what inputs, this implementation will _always_ double count every element except for the first and the last (try playing around with the inputs to convince yourself).

So why are we double counting in the first place? If we look at the first two subarrays, we see there's a lot of overlap:

<Visualizer>
  <Figures.Comparison />
</Visualizer>

What if, on each step, we only take into account the _differences_ instead? In other words, is there a way to get the sum of the second subarray from the sum of the first? If so, we would be able to _derive_ the sum of the second subarray rather than recounting every element again.

In the example above, we can get the sum of the **second subarray by subtracting 1 and adding 5** to the sum of the first.

<Visualizer
  initialInputs={[[1, 2, 3, 4]]}
  algorithm={snapshot((arr) => {
    let window = [0, 3]
    let sum = 0
    arr.slice(...window).forEach((item) => (sum += item))
    debugger
    let diff = -arr[0]
    window = [1, 3]
    sum -= arr[0]
    debugger
    diff = arr[3]
    window = [1, 4]
    sum += arr[3]
    debugger
  })}
  delay={700}
>
  {({ state }) => <Figures.Derive state={state} />}
</Visualizer>

This reduces the sum computation from `k` iterations to only one iteration! This is also where the sliding window namesake comes from‚Äîit's as if we have a window of 4 items that we _slide_ to the next subarray.

Maybe adding a border around the items would make the window more clear:

<Visualizer
  initialInputs={[[1, 2, 3, 4]]}
  algorithm={snapshot((arr) => {
    let sum = 0
    let window = [0, 3]
    arr.slice(...window).forEach((item) => (sum += item))
    debugger
    sum = 0
    window = [1, 4]
    arr.slice(...window).forEach((item) => (sum += item))
    debugger
  })}
  delay={700}
  controls
>
  {({ state }) => <Figures.Window state={state} />}
</Visualizer>

With this key insight let's rewrite the algorithm. Remember that the algorithm receives two inputs - an array of numbers `arr` and a size of subarray `k`.

1. At the start, we _build_ the window‚Äîiterate until our window contains `k` items‚Äîwhile keeping track of the sum.
2. Then, we _slide_ the window one item over, updating the sum by subtracting the item no longer in the window and adding the item that was added to the window. By doing this we ensure that the sum stays in sync with the items that are in the window.
3. With this sum we can compute the average as before.

<Visualizer
  initialInputs={[[1, 2, 3, 4, 5, 6], 3]}
  algorithm={snapshot((arr, k) => {
    const result = []
    let windowStart = 0
    let windowSum = 0
    for (let windowEnd = 0; windowEnd < arr.length; windowEnd++) {
      windowSum += arr[windowEnd]
      debugger
      if (windowEnd >= k - 1) {
        result.push((windowSum / k).toFixed(2))
        windowSum -= arr[windowStart]
        windowStart++
      }
    }
    debugger
    return result
  })}
  delay={600}
  controls
  editable
>
  {({ state }) => <Figures.Optimal state={state} />}
</Visualizer>

And that's the find all averages problem using the sliding window pattern! Notice how this implementation only needs 7 steps to calculate the sum instead of 13 with the previous implementation. Now that doesn't seem to be too big of a difference, but look how blazing fast the optimal implementation is compared to our previous one:

<Visualizer
  initialInputs={[[1, 3, 2, 6, -1, 4, 1, 8, 2], 3]}
  caption="The animation speed is set to 400ms for both implementations!"
  editable
  algorithm={[
    snapshot((arr, k) => {
      const result = []
      let windowStart = 0
      let windowSum = 0
      for (let windowEnd = 0; windowEnd < arr.length; windowEnd++) {
        windowSum += arr[windowEnd]
        debugger
        if (windowEnd >= k - 1) {
          result.push(windowSum / k)
          windowSum -= arr[windowStart]
          windowStart++
        }
      }
      debugger
      return result
    }),
    snapshot((arr, k) => {
      const result = []
      for (let i = 0; i <= arr.length - k; i++) {
        let sum = 0
        for (let j = 0; j < k; j++) {
          sum += arr[i + j]
          debugger
        }
        result.push(sum / k)
      }
      debugger
      return result
    }),
  ]}
>
  {({ state: [optimal, quadratic], inputs }) => (
    <React.Fragment>
      <h3 className="text-gray-500 font-semibold text-center">Optimal üèé</h3>
      <Figures.OptimalMin state={optimal} />
      <h3 className="text-gray-500 font-semibold text-center my-8">Naive üêå</h3>
      <Figures.Quadratic state={quadratic} />
    </React.Fragment>
  )}
</Visualizer>

While the window is building, both algorithms are going at the same pace (try changing the size of k to equal to the size of the array‚Äîboth algorithms will finish at the same time!). However, once the window is complete, the optimal algorithm blazes off and terminates in less than half the time it takes for the naive algorithm to finish.

## A note on time complexity

Admittedly comparing the runtime of two algorithms from an animated graphic isn't necessarily correct. Some algorithms naturally perform better on some inputs than others. The correct approach is to compare the algorithms' respective [time complexities](https://en.wikipedia.org/wiki/Time_complexity#:~:text=In%20computer%20science%2C%20the%20time,takes%20to%20run%20an%20algorithm.).

I wanted to avoid talking about time complexity for those not familiar with it, but I do think it's important to note what the time complexities actually _are_ for those who are curious.

**TL;DR**‚ÄîThe naive implementation is `O(nk)` while the optimal implementation is `O(n)`, where `n` is the size of the given array `arr`.

In the naive implementation, for every item in the array, we iterate `k` times to compute the subarray. This gives us a runtime of `O(nk)` where `n` is the size of the given array.

In the optimal implementation, we broke down the algorithm into two concrete steps‚Äîthe build step and the slide step. The time complexity of the algorithm is thus the sum of the build step and the slide step.

The build step is simply `O(k)` because we're only iterating until we reach the window size `k`. At a quick glance, the slide step is `O(n)` because we're iterating until the end of the array. However, we don't start at index `0`‚Äîwe start at index `k`. Therefore a more tight upper bound is `O(n - k)`. Adding the two together we get the final runtime of `O(n)`. A surprising find! Turns out the runtime of the optimal solution isn't reliant on the value of `k` at all.
